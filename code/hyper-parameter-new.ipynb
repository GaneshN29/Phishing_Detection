{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7967469,"sourceType":"datasetVersion","datasetId":4687828},{"sourceId":7967475,"sourceType":"datasetVersion","datasetId":4687833},{"sourceId":7967483,"sourceType":"datasetVersion","datasetId":4687839},{"sourceId":8047337,"sourceType":"datasetVersion","datasetId":4745320}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport os\nimport cv2\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.keras.models import Model\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\n\n%matplotlib inline\n\nimport pandas as pd\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns_of_interest  = [\n    \"qty_slash_url\",\n    \"time_domain_activation\",\n    \"length_url\",\n    \"qty_mx_servers\",\n    \"qty_dot_directory\",\n    \"qty_dot_domain\",\n    \"url_shortened\",\n    \"directory_length\",\n    \"file_length\",\n    \"tls_ssl_certificate\",\n    \"qty_nameservers\",\n    \"qty_at_params\",\n    \"qty_ip_resolved\",\n    \"tld_present_params\",\n    \"qty_hyphen_domain\",\n    \"qty_at_url\",\n    \"qty_vowels_domain\",\n    \"qty_hyphen_url\",\n    \"time_domain_expiration\",\n    \"domain_spf\"\n]\nbest_model='feed_forward'","metadata":{"id":"jTzMzwNCZNsL","execution":{"iopub.status.busy":"2024-05-06T06:19:15.191183Z","iopub.execute_input":"2024-05-06T06:19:15.193599Z","iopub.status.idle":"2024-05-06T06:19:15.203497Z","shell.execute_reply.started":"2024-05-06T06:19:15.193557Z","shell.execute_reply":"2024-05-06T06:19:15.202211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculate_accur(predictions, actual_results):\n    # Initialize a variable to count the number of correct predictions\n    correct_predictions = 0\n\n    # Iterate through each prediction and actual result\n    for pred, actual in zip(predictions, actual_results):\n        # Check if the prediction matches the actual result\n        if pred == actual:\n            # If so, increment the count of correct predictions\n            correct_predictions += 1\n\n    # Calculate accuracy by dividing the number of correct predictions by the total number of predictions\n    accuracy = (correct_predictions / len(predictions)) * 100\n    return accuracy\n","metadata":{"id":"FWYpDVYilOY7","execution":{"iopub.status.busy":"2024-05-06T06:19:16.152959Z","iopub.execute_input":"2024-05-06T06:19:16.153958Z","iopub.status.idle":"2024-05-06T06:19:16.159826Z","shell.execute_reply.started":"2024-05-06T06:19:16.153914Z","shell.execute_reply":"2024-05-06T06:19:16.159115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.optimizers import SGD, Adam\nfrom keras.regularizers import l1, l2\n\ndef create_feedforward_neural_network(input_dim, num_hidden_layers, num_neurons, activation, dropout_rate, l1_reg, l2_reg, learning_rate):\n    model = Sequential()\n    model.add(Dense(num_neurons, input_dim=input_dim, activation=activation, kernel_regularizer=l1(l1_reg), kernel_initializer=GlorotUniform()))\n    for _ in range(num_hidden_layers):\n        model.add(Dense(num_neurons, activation=activation, kernel_regularizer=l2(l2_reg), kernel_initializer=GlorotUniform()))\n        model.add(Dropout(dropout_rate))\n    model.add(Dense(1, activation='sigmoid'))\n    \n    # Define optimizer with custom learning rate\n    optimizer = Adam(learning_rate=learning_rate)\n    \n    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n    return model\n\ndef preprocess_data(csv_path, columns_of_interest, test_size):\n    # Read the CSV file into a DataFrame\n    df = pd.read_csv(csv_path)\n\n    # Replace -1 with mean values\n    for col in df.columns:\n        if -1 in df[col].unique():\n            mean_value = int(df[col][df[col] != -1].mean())\n            df[col] = df[col].replace(-1, mean_value)\n\n    target_column = 'phishing'\n    x = df.drop(target_column, axis=1)\n    scaler = MinMaxScaler()\n\n    # Apply Min-Max scaling to each column\n    for col in x.columns:\n        column_values = x[col].values.reshape(-1, 1)\n        x[col] = scaler.fit_transform(column_values)\n\n    df = pd.concat([x, df[target_column]], axis=1)\n\n    X = df.drop('phishing', axis=1)\n    y = df['phishing'].values\n\n    selected_columns = X[columns_of_interest].values\n\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(selected_columns, y, test_size=test_size, random_state=42)\n\n    return X_train, X_test, y_train, y_test\n\ndef train_and_test_model(X_train, y_train, X_test, y_test, epochs, input_dim, optimizer, learning_rate, num_hidden_layers, num_neurons, activation_function, dropout_rate, l1_reg, l2_reg):\n    model = Sequential()\n    model.add(Dense(num_neurons, input_dim=input_dim, activation=activation_function, kernel_regularizer=l1(l1_reg), kernel_initializer='glorot_uniform'))\n    for _ in range(num_hidden_layers):\n        model.add(Dense(num_neurons, activation=activation_function, kernel_regularizer=l2(l2_reg), kernel_initializer='glorot_uniform'))\n        model.add(Dropout(dropout_rate))\n    model.add(Dense(1, activation='sigmoid'))\n    \n    # Define optimizer with custom learning rate\n    if optimizer == 'SGD':\n        opt = SGD(learning_rate=learning_rate)  # Adjusted here\n    else:\n        opt = Adam(learning_rate=learning_rate)  # Adjusted here\n    \n    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n    \n    model.fit(X_train, y_train, epochs=epochs, batch_size=64, verbose=0)  # Batch size set to 64 as an example\n\n    y_pred = model.predict(X_test, verbose=0)\n    threshold = 0.5\n\n    # Calculate metrics\n    y_pred_binary = (y_pred > threshold).astype(int)\n    accuracy = accuracy_score(y_test, y_pred_binary)\n    \n    return accuracy, model\n\n\ndef predict_with_model(model, features, actual_results):\n    features = features.reshape((features.shape[0], features.shape[2]))\n    #print(features[0])\n    y_pred_prob = model.predict(features,verbose=0)\n    \n    threshold = 0.5\n    y_pred = (y_pred_prob > threshold).astype(int)\n\n    accuracy = calculate_accur(y_pred, actual_results)\n    return accuracy\n\ndef grid_hyperparameter_tuning(csv_paths, columns_of_interest_range, epochs_range, testing_sizes, learning_rates, batch_sizes, optimizers, num_hidden_layers_range, num_neurons_range, activation_functions, dropout_rates, l1_regs, l2_regs):\n    results = []\n    best_accuracy = 0.0\n    for csv_path in csv_paths:\n        for columns_of_interest_number in range(columns_of_interest_range[0], columns_of_interest_range[1] + 1):\n            for epochs in epochs_range:\n                for test_size in testing_sizes:\n                    for learning_rate in learning_rates:\n                        for batch_size in batch_sizes:\n                            for optimizer in optimizers:\n                                for num_hidden_layers in range(num_hidden_layers_range[0], num_hidden_layers_range[1] + 1):\n                                    for num_neurons in num_neurons_range:\n                                        for activation_function in activation_functions:\n                                            for dropout_rate in dropout_rates:\n                                                for l1_reg in l1_regs:\n                                                    for l2_reg in l2_regs:\n                                                        X_train, X_test, y_train, y_test = preprocess_data(csv_path, columns_of_interest[:columns_of_interest_number], test_size)\n                                                        accuracy, model = train_and_test_model(X_train, y_train, X_test, y_test, epochs, X_train.shape[1], optimizer, learning_rate, num_hidden_layers, num_neurons, activation_function, dropout_rate, l1_reg, l2_reg)\n\n                                                        ds = pd.read_csv(csv_path)\n                                                        V = ds[columns_of_interest[:columns_of_interest_number]]\n\n                                                        mean_values = V.replace(-1, np.nan).mean(axis=0)\n                                                        dataset = pd.read_csv('/kaggle/input/newnew/features_dataset_new.csv')\n                                                        v_copy = dataset.drop('phishing', axis=1).replace(-1, np.nan)\n                                                        v_copy.fillna(mean_values, inplace=True)\n                                                        v_copy = v_copy.iloc[:, :columns_of_interest_number]\n                                                        features = v_copy.values\n\n                                                        min_values = V.replace(-1, np.nan).min(axis=0)\n                                                        max_values = V.max(axis=0)\n                                                        scaled_features = []\n\n                                                        for row in features:\n                                                            filtered_row = row[row != -1]\n                                                            scaler = MinMaxScaler()\n                                                            scaler.fit([min_values, max_values])\n                                                            scaled_row = scaler.transform([filtered_row])\n                                                            scaled_features.append(scaled_row)\n\n                                                        scaled_example = np.array(scaled_features)\n\n                                                        accuracy_on_new_data = predict_with_model(model, scaled_example, dataset['phishing'])\n                                                        if accuracy_on_new_data > best_accuracy:\n                                                            best_accuracy = accuracy_on_new_data\n                                                            best_model_name = f\"/kaggle/working/{best_accuracy}.h5\"\n                                                            model.save(best_model_name)\n                                                        parameters = {\n                                                            \"csv_path\": csv_path,\n                                                            \"columns_of_interest\": columns_of_interest_number,\n                                                            \"epochs\": epochs,\n                                                            \"test_size\": test_size,\n                                                            \"learning_rate\": learning_rate,\n                                                            \"batch_size\": batch_size,\n                                                            \"optimizer\": optimizer,\n                                                            \"num_hidden_layers\": num_hidden_layers,\n                                                            \"num_neurons\": num_neurons,\n                                                            \"activation_function\": activation_function,\n                                                            \"dropout_rate\": dropout_rate,\n                                                            \"l1_reg\": l1_reg,\n                                                            \"l2_reg\": l2_reg,\n                                                            \"accuracy_on_data\": accuracy,\n                                                            \"accuracy_on_new_data\": accuracy_on_new_data\n                                                        }\n                                                        print(parameters)\n                                                        results.append(parameters)\n    return results\n\n# Define parameters\ncsv_paths = ['/kaggle/input/zzzzzz/mendeley_dataset_full.csv',\n             '/kaggle/input/ssssssss/dataset_small.csv']\ncolumns_of_interest_range = [14, 20]\nepochs_range = [10, 20, 30, 40, 50]\ntesting_sizes = [0.5, 0.4, 0.3, 0.2]\nlearning_rates = [0.001, 0.01, 0.1]\nbatch_sizes = [32, 64, 128]\noptimizers = ['SGD', 'Adam']\nnum_hidden_layers_range = [1, 3]\nnum_neurons_range = [64, 128, 256]\nactivation_functions = ['relu', 'tanh']\ndropout_rates = [0.0, 0.1, 0.2]\nl1_regs = [0.0, 0.01, 0.1]\nl2_regs = [0.0, 0.01, 0.1]\n\n# Perform grid-based hyperparameter tuning\nresults = grid_hyperparameter_tuning(csv_paths, columns_of_interest_range, epochs_range, testing_sizes, learning_rates, batch_sizes, optimizers, num_hidden_layers_range, num_neurons_range, activation_functions, dropout_rates, l1_regs, l2_regs)\n\n# Print results\nfor result in results:\n    print(result)\n","metadata":{"id":"AOPBEIUpY448","outputId":"26d0c9d6-d4b7-4630-a8e3-fe1c7e3c9eec","execution":{"iopub.status.busy":"2024-05-07T04:34:15.963155Z","iopub.execute_input":"2024-05-07T04:34:15.963844Z","iopub.status.idle":"2024-05-07T04:34:16.925221Z","shell.execute_reply.started":"2024-05-07T04:34:15.963808Z","shell.execute_reply":"2024-05-07T04:34:16.923721Z"},"trusted":true},"execution_count":2,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 180\u001b[0m\n\u001b[1;32m    177\u001b[0m l2_regs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.1\u001b[39m]\n\u001b[1;32m    179\u001b[0m \u001b[38;5;66;03m# Perform grid-based hyperparameter tuning\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_hyperparameter_tuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns_of_interest_range\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs_range\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtesting_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_hidden_layers_range\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_neurons_range\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation_functions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_rates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml1_regs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_regs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# Print results\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n","Cell \u001b[0;32mIn[2], line 111\u001b[0m, in \u001b[0;36mgrid_hyperparameter_tuning\u001b[0;34m(csv_paths, columns_of_interest_range, epochs_range, testing_sizes, learning_rates, batch_sizes, optimizers, num_hidden_layers_range, num_neurons_range, activation_functions, dropout_rates, l1_regs, l2_regs)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l1_reg \u001b[38;5;129;01min\u001b[39;00m l1_regs:\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m l2_reg \u001b[38;5;129;01min\u001b[39;00m l2_regs:\n\u001b[0;32m--> 111\u001b[0m         X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m preprocess_data(csv_path, \u001b[43mcolumns_of_interest\u001b[49m[:columns_of_interest_number], test_size)\n\u001b[1;32m    112\u001b[0m         accuracy, model \u001b[38;5;241m=\u001b[39m train_and_test_model(X_train, y_train, X_test, y_test, epochs, X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], optimizer, learning_rate, num_hidden_layers, num_neurons, activation_function, dropout_rate, l1_reg, l2_reg)\n\u001b[1;32m    114\u001b[0m         ds \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(csv_path)\n","\u001b[0;31mNameError\u001b[0m: name 'columns_of_interest' is not defined"],"ename":"NameError","evalue":"name 'columns_of_interest' is not defined","output_type":"error"}]},{"cell_type":"code","source":"best_result = max(results, key=lambda x: x['accuracy_on_new_data'])\n\n# Print the parameters of the best result\nprint(\"Best Result:\")\nfor key, value in best_result.items():\n    print(f\"{key}: {value}\")","metadata":{"id":"us2GDVOzrW97","execution":{"iopub.status.busy":"2024-03-28T18:39:18.511374Z","iopub.execute_input":"2024-03-28T18:39:18.511847Z","iopub.status.idle":"2024-03-28T18:39:18.564857Z","shell.execute_reply.started":"2024-03-28T18:39:18.511809Z","shell.execute_reply":"2024-03-28T18:39:18.563378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"JyCia1nwrXjI","executionInfo":{"status":"error","timestamp":1711641980003,"user_tz":-330,"elapsed":432,"user":{"displayName":"project h","userId":"02799284407731197507"}},"outputId":"30cc86d1-95a8-4bb6-a082-ccd0091fbe75","execution":{"iopub.status.busy":"2024-03-29T10:21:37.050323Z","iopub.execute_input":"2024-03-29T10:21:37.050670Z","iopub.status.idle":"2024-03-29T10:21:37.107796Z","shell.execute_reply.started":"2024-03-29T10:21:37.050641Z","shell.execute_reply":"2024-03-29T10:21:37.106603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"UpEHHLL0z-Z2"},"execution_count":null,"outputs":[]}]}