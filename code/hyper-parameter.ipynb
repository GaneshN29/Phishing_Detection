{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7967469,"sourceType":"datasetVersion","datasetId":4687828},{"sourceId":7967475,"sourceType":"datasetVersion","datasetId":4687833},{"sourceId":7967483,"sourceType":"datasetVersion","datasetId":4687839},{"sourceId":8047337,"sourceType":"datasetVersion","datasetId":4745320}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.keras.models import Model\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\n\n%matplotlib inline\n\nimport pandas as pd\n","metadata":{"execution":{"iopub.status.busy":"2024-04-29T14:41:06.289549Z","iopub.execute_input":"2024-04-29T14:41:06.290219Z","iopub.status.idle":"2024-04-29T14:41:22.341879Z","shell.execute_reply.started":"2024-04-29T14:41:06.290186Z","shell.execute_reply":"2024-04-29T14:41:22.340765Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-04-29 14:41:10.258740: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-29 14:41:10.258836: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-29 14:41:10.414490: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Dense, Concatenate\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.models import Sequential\n# Model 1: Feedforward Neural Network (FNN)\ndef create_feedforward_neural_network(input_dim):\n    model = Sequential()\n    model.add(Dense(128, input_dim=input_dim, activation='relu'))\n    model.add(Dense(64, activation='relu'))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n    return model","metadata":{"id":"SW5v2La2ZFts","execution":{"iopub.status.busy":"2024-04-29T14:41:22.343849Z","iopub.execute_input":"2024-04-29T14:41:22.344429Z","iopub.status.idle":"2024-04-29T14:41:22.352448Z","shell.execute_reply.started":"2024-04-29T14:41:22.344399Z","shell.execute_reply":"2024-04-29T14:41:22.351366Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"","metadata":{"executionInfo":{"elapsed":124823,"status":"ok","timestamp":1711617697200,"user":{"displayName":"project h","userId":"02799284407731197507"},"user_tz":-330},"id":"mxcR6AKmZHoq","outputId":"e9c88e9a-3b06-4da2-f108-7c45edce111f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns_of_interest  = [\n    \"qty_slash_url\",\n    \"length_url\",\n    \"qty_mx_servers\",\n    \"qty_dot_directory\",\n    \"qty_dot_domain\",\n    \"url_shortened\",\n    \"directory_length\",\n    \"file_length\",\n    \"tls_ssl_certificate\",\n    \"qty_nameservers\",\n    \"qty_at_params\",\n    \"qty_ip_resolved\",\n    \"tld_present_params\",\n    \"qty_hyphen_domain\",\n    \"qty_at_url\",\n    \"qty_vowels_domain\",\n    \"qty_hyphen_url\",\n    \"time_domain_expiration\",\n    \"domain_spf\"\n]\nbest_model='feed_forward'","metadata":{"id":"jTzMzwNCZNsL","execution":{"iopub.status.busy":"2024-04-29T14:41:22.353679Z","iopub.execute_input":"2024-04-29T14:41:22.354771Z","iopub.status.idle":"2024-04-29T14:41:22.363270Z","shell.execute_reply.started":"2024-04-29T14:41:22.354742Z","shell.execute_reply":"2024-04-29T14:41:22.362320Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def calculate_accur(predictions, actual_results):\n    # Initialize a variable to count the number of correct predictions\n    correct_predictions = 0\n\n    # Iterate through each prediction and actual result\n    for pred, actual in zip(predictions, actual_results):\n        # Check if the prediction matches the actual result\n        if pred == actual:\n            # If so, increment the count of correct predictions\n            correct_predictions += 1\n\n    # Calculate accuracy by dividing the number of correct predictions by the total number of predictions\n    accuracy = (correct_predictions / len(predictions)) * 100\n    return accuracy\n","metadata":{"id":"FWYpDVYilOY7","execution":{"iopub.status.busy":"2024-04-29T14:41:22.365719Z","iopub.execute_input":"2024-04-29T14:41:22.366387Z","iopub.status.idle":"2024-04-29T14:41:22.374582Z","shell.execute_reply.started":"2024-04-29T14:41:22.366351Z","shell.execute_reply":"2024-04-29T14:41:22.373578Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nimport joblib\ndef preprocess_data(csv_path, columns_of_interest, test_size):\n    # Read the CSV file into a DataFrame\n    df = pd.read_csv(csv_path)\n\n    # Replace -1 with mean values\n    for col in df.columns:\n        if -1 in df[col].unique():\n            mean_value = int(df[col][df[col] != -1].mean())\n            df[col] = df[col].replace(-1, mean_value)\n\n    target_column = 'phishing'\n    x = df.drop(target_column, axis=1)\n    scaler = MinMaxScaler()\n\n    # Apply Min-Max scaling to each column\n    for col in x.columns:\n        column_values = x[col].values.reshape(-1, 1)\n        x[col] = scaler.fit_transform(column_values)\n\n    df = pd.concat([x, df[target_column]], axis=1)\n\n    X = df.drop('phishing', axis=1)\n    y = df['phishing'].values\n\n    selected_columns = X[columns_of_interest].values\n\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(selected_columns, y, test_size=test_size, random_state=42)\n\n    return X_train, X_test, y_train, y_test\n\n\n\ndef train_and_test_model(X_train, y_train, X_test, y_test, epochs, input_dim):\n    model = create_feedforward_neural_network(input_dim)\n    model.fit(X_train, y_train, epochs=epochs, batch_size=64,verbose=0)\n    #print(X_test.shape)\n    y_pred = model.predict(X_test,verbose=0)\n    threshold = 0.5\n\n    # Calculate metrics\n    y_pred_binary = (y_pred > threshold).astype(int)\n    accuracy = accuracy_score(y_test, y_pred_binary)\n    return accuracy, model\n\ndef predict_with_model(model, features, actual_results):\n    features = features.reshape((features.shape[0], features.shape[2]))\n    #print(features[0])\n    y_pred_prob = model.predict(features,verbose=0)\n    \n    threshold = 0.5\n    y_pred = (y_pred_prob > threshold).astype(int)\n\n    accuracy = calculate_accur(y_pred, actual_results)\n    return accuracy\n\ndef grid_hyperparameter_tuning(csv_paths, columns_of_interest_range, epochs_range, testing_sizes):\n    results = []\n    best_accuracy = 0.0\n    for csv_path in csv_paths:\n        for columns_of_interest_number in range(columns_of_interest_range[0], columns_of_interest_range[1] + 1):\n            for epochs in epochs_range:\n                for test_size in testing_sizes:\n                    X_train, X_test, y_train, y_test = preprocess_data(csv_path, columns_of_interest[:columns_of_interest_number], test_size)\n                    accuracy, model = train_and_test_model(X_train, y_train, X_test, y_test, epochs, X_train.shape[1])\n\n\n                    ds = pd.read_csv(csv_path)\n                    V = ds[columns_of_interest[:columns_of_interest_number]]\n\n                    mean_values = V.replace(-1, np.nan).mean(axis=0)\n                    dataset = pd.read_csv('/kaggle/input/newnew/features_dataset_new.csv')\n                    dataset = dataset.drop(columns=['time_domain_activation'])\n                    \n                    v_copy = dataset.drop('phishing', axis=1).replace(-1, np.nan)\n                    v_copy.fillna(mean_values, inplace=True)\n                    v_copy = v_copy.iloc[:, :columns_of_interest_number]\n                    print(v_copy.head())\n                    features = v_copy.values\n\n                    min_values = V.replace(-1, np.nan).min(axis=0)\n                    max_values = V.max(axis=0)\n                    scaled_features = []\n\n                    for row in features:\n                        filtered_row = row[row != -1]\n                        scaler = MinMaxScaler()\n                        scaler.fit([min_values, max_values])\n                        scaled_row = scaler.transform([filtered_row])\n                        scaled_features.append(scaled_row)\n\n                    scaled_example = np.array(scaled_features)\n                    \n                    accuracy_on_new_data = predict_with_model(model,scaled_example, dataset['phishing'])\n                    if accuracy_on_new_data > best_accuracy:\n                        best_accuracy = accuracy_on_new_data\n                        best_model_name = f\"/kaggle/working/{best_accuracy}.h5\"\n                        model.save(best_model_name)\n                    parameters = {\n                        \"csv_path\": csv_path,\n                        \"columns_of_interest\": columns_of_interest_number,\n                        \"epochs\": epochs,\n                        \"test_size\": test_size,\n                        \"accuracy_on_validation_data\": accuracy,\n                        \"accuracy_on_new_data\": accuracy_on_new_data\n                    }\n                    print(parameters)\n                    results.append(parameters)\n    return results\n\n# Define parameters\ncsv_paths = ['/kaggle/input/zzzzzz/mendeley_dataset_full.csv',\n             '/kaggle/input/ssssssss/dataset_small.csv']\ncolumns_of_interest_range = [13, 19]\nepochs_range = [10, 20, 30, 40, 50]\ntesting_sizes = [0.5, 0.4, 0.3, 0.2]\n\n# Perform grid-based hyperparameter tuning\nresults = grid_hyperparameter_tuning(csv_paths, columns_of_interest_range, epochs_range, testing_sizes)\n# Print results\nfor result in results:\n    print(result)\n","metadata":{"id":"AOPBEIUpY448","outputId":"26d0c9d6-d4b7-4630-a8e3-fe1c7e3c9eec","execution":{"iopub.status.busy":"2024-04-29T14:41:22.375761Z","iopub.execute_input":"2024-04-29T14:41:22.376596Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"   qty_slash_url  length_url  qty_mx_servers  qty_dot_directory  \\\n0              3          37               1                  1   \n1              5          77               5                  0   \n2              5         126               0                  0   \n3              2          18               8                  0   \n4              5          55               5                  0   \n\n   qty_dot_domain  url_shortened  directory_length  file_length  \\\n0               2              0                 2           10   \n1               1              0                 4           32   \n2               4              0                 4            0   \n3               2              0                 1            0   \n4               2              0                 4            0   \n\n   tls_ssl_certificate  qty_nameservers  qty_at_params  qty_ip_resolved  \\\n0                    1              2.0              0         1.000000   \n1                    1              2.0              0         2.000000   \n2                    0              0.0              0         1.249566   \n3                    1              4.0              0         1.000000   \n4                    1              4.0              0         2.000000   \n\n   tld_present_params  \n0                   0  \n1                   0  \n2                   0  \n3                   0  \n4                   0  \n{'csv_path': '/kaggle/input/zzzzzz/mendeley_dataset_full.csv', 'columns_of_interest': 13, 'epochs': 10, 'test_size': 0.5, 'accuracy_on_validation_data': 0.9107030051439401, 'accuracy_on_new_data': 53.75328083989501}\n","output_type":"stream"}]},{"cell_type":"code","source":"best_result = max(results, key=lambda x: x['accuracy_on_new_data'])\n\n# Print the parameters of the best result\nprint(\"Best Result:\")\nfor key, value in best_result.items():\n    print(f\"{key}: {value}\")","metadata":{"id":"us2GDVOzrW97","execution":{"iopub.status.busy":"2024-03-28T18:39:18.511374Z","iopub.execute_input":"2024-03-28T18:39:18.511847Z","iopub.status.idle":"2024-03-28T18:39:18.564857Z","shell.execute_reply.started":"2024-03-28T18:39:18.511809Z","shell.execute_reply":"2024-03-28T18:39:18.563378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"JyCia1nwrXjI","executionInfo":{"status":"error","timestamp":1711641980003,"user_tz":-330,"elapsed":432,"user":{"displayName":"project h","userId":"02799284407731197507"}},"outputId":"30cc86d1-95a8-4bb6-a082-ccd0091fbe75","execution":{"iopub.status.busy":"2024-03-29T10:21:37.050323Z","iopub.execute_input":"2024-03-29T10:21:37.050670Z","iopub.status.idle":"2024-03-29T10:21:37.107796Z","shell.execute_reply.started":"2024-03-29T10:21:37.050641Z","shell.execute_reply":"2024-03-29T10:21:37.106603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"UpEHHLL0z-Z2"},"execution_count":null,"outputs":[]}]}